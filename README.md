# cuda-image-processing
This is my attempt to learn more about CUDA and GPUs in a fun way by applying user-inputted convolution masks (defined in CSV format) to images. At first, the CUDA kernel I created for applying the convolution mask used exclusively global memory. I then attempted a shared memory implementation that partitions the image into tiles and ensures that any halo rows required for the convolution are included in each block.

I avoided researching any tiling solutions to this task for the sake of problem solving, so there is likely a more efficient solution than my approach. While I do decrease the number of global memory accesses (and increase compute to global memory access ratio) substantially, I rarely see better performance over my global memory approach. I think this is likely due to coalesced memory accesses in the global memory implementation, which will occur because neighbouring threads access contiguous locations in memory throughout the convolution process.
